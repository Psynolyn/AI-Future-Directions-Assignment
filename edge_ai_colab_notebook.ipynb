{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb602ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "SEED = 1234\n",
    "tf.random.set_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)\n",
    "OUTDIR = '/content/outputs'\n",
    "os.makedirs(OUTDIR, exist_ok=True)\n",
    "os.makedirs(os.path.join(OUTDIR, 'model'), exist_ok=True)\n",
    "os.makedirs(os.path.join(OUTDIR, 'tflite'), exist_ok=True)\n",
    "print('Output dir:', OUTDIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6da80687",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
    "y_train = y_train.flatten()\n",
    "y_test = y_test.flatten()\n",
    "IMAGE_SIZE = (96, 96)\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 8\n",
    "NUM_CLASSES = 10\n",
    "def preprocess_images(x):\n",
    "    x = tf.image.resize(x, IMAGE_SIZE)\n",
    "    x = tf.cast(x, tf.float32) / 255.0\n",
    "    return x\n",
    "x_train_proc = preprocess_images(x_train)\n",
    "x_test_proc = preprocess_images(x_test)\n",
    "fig, axes = plt.subplots(2,5, figsize=(12,5))\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    ax.imshow(x_train[i])\n",
    "    ax.set_title(str(y_train[i]))\n",
    "    ax.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8f49e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers, models\n",
    "\n",
    "def build_model(input_shape=(96,96,3), num_classes=10, alpha=0.35):\n",
    "    base = tf.keras.applications.MobileNetV2(input_shape=input_shape, include_top=False, weights=None, alpha=alpha)\n",
    "    x = base.output\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    x = layers.Dropout(0.2)(x)\n",
    "    outputs = layers.Dense(num_classes, activation='softmax')(x)\n",
    "    model = models.Model(inputs=base.input, outputs=outputs)\n",
    "    return model\n",
    "\n",
    "model = build_model(input_shape=(IMAGE_SIZE[0], IMAGE_SIZE[1], 3), num_classes=NUM_CLASSES)\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(1e-3), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d9a129b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = tf.data.Dataset.from_tensor_slices((x_train_proc, y_train))\n",
    "test_ds = tf.data.Dataset.from_tensor_slices((x_test_proc, y_test))\n",
    "train_ds = train_ds.shuffle(5000).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "test_ds = test_ds.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "callbacks = [\n",
    "    tf.keras.callbacks.ModelCheckpoint(os.path.join(OUTDIR, 'model', 'best_model.h5'), save_best_only=True, monitor='val_accuracy'),\n",
    "    tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=3, restore_best_weights=True)\n",
    "]\n",
    "history = model.fit(train_ds, epochs=EPOCHS, validation_data=test_ds, callbacks=callbacks)\n",
    "model.save(os.path.join(OUTDIR, 'model', 'final_model.h5'))\n",
    "model.save(os.path.join(OUTDIR, 'model', 'saved_model'))\n",
    "loss, acc = model.evaluate(test_ds)\n",
    "print(f'Final test loss: {loss:.4f}, test accuracy: {acc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80e27e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def representative_data_gen(x_data, image_size, num_samples=200):\n",
    "    for i in range(min(num_samples, x_data.shape[0])):\n",
    "        img = x_data[i]\n",
    "        img = tf.image.resize(img, image_size)\n",
    "        img = tf.cast(img, tf.float32) / 255.0\n",
    "        img = tf.expand_dims(img, 0)\n",
    "        yield [img]\n",
    "saved_model_dir = os.path.join(OUTDIR, 'model', 'saved_model')\n",
    "tflite_out = os.path.join(OUTDIR, 'tflite')\n",
    "converter = tf.lite.TFLiteConverter.from_saved_model(saved_model_dir)\n",
    "tflite_model = converter.convert()\n",
    "open(os.path.join(tflite_out, 'model_float32.tflite'), 'wb').write(tflite_model)\n",
    "converter = tf.lite.TFLiteConverter.from_saved_model(saved_model_dir)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "tflite_model = converter.convert()\n",
    "open(os.path.join(tflite_out, 'model_dynamic_quant.tflite'), 'wb').write(tflite_model)\n",
    "converter = tf.lite.TFLiteConverter.from_saved_model(saved_model_dir)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter.representative_dataset = lambda: representative_data_gen(x_train, IMAGE_SIZE, num_samples=200)\n",
    "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "converter.inference_input_type = tf.uint8\n",
    "converter.inference_output_type = tf.uint8\n",
    "try:\n",
    "    tflite_model = converter.convert()\n",
    "    open(os.path.join(tflite_out, 'model_int8_fullquant.tflite'), 'wb').write(tflite_model)\n",
    "    print('Saved model_int8_fullquant.tflite')\n",
    "except Exception as e:\n",
    "    print('Full integer quantization failed:', e)\n",
    "for fname in os.listdir(tflite_out):\n",
    "    fpath = os.path.join(tflite_out, fname)\n",
    "    print(fname, '-', os.path.getsize(fpath) / 1024.0, 'KB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "588b45e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "def evaluate_tflite_model(tflite_path, x_test, y_test, image_size):\n",
    "    interpreter = tf.lite.Interpreter(model_path=str(tflite_path))\n",
    "    interpreter.allocate_tensors()\n",
    "    input_details = interpreter.get_input_details()\n",
    "    output_details = interpreter.get_output_details()\n",
    "    dtype = input_details[0]['dtype']\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    for i in range(len(x_test)):\n",
    "        img = x_test[i]\n",
    "        if dtype == np.uint8:\n",
    "            inp = (img * 255).astype(np.uint8)\n",
    "        else:\n",
    "            inp = img.astype(np.float32)\n",
    "        inp = np.expand_dims(inp, 0)\n",
    "        interpreter.set_tensor(input_details[0]['index'], inp)\n",
    "        interpreter.invoke()\n",
    "        out = interpreter.get_tensor(output_details[0]['index'])\n",
    "        pred = np.argmax(out[0])\n",
    "        if pred == int(y_test[i]):\n",
    "            correct += 1\n",
    "        total += 1\n",
    "    acc = correct / total\n",
    "    return acc, correct, total\n",
    "\n",
    "tflite_dir = Path(tflite_out)\n",
    "results = {}\n",
    "import json\n",
    "for tfile in tflite_dir.glob('*.tflite'):\n",
    "    acc, c, t = evaluate_tflite_model(tfile, x_test_proc.numpy(), y_test, IMAGE_SIZE)\n",
    "    results[tfile.name] = {'accuracy': acc, 'correct': int(c), 'total': int(t), 'size_kb': os.path.getsize(tfile) / 1024.0}\n",
    "    print(f\"{tfile.name}: accuracy={acc:.4f} ({c}/{t}) size={results[tfile.name]['size_kb']:.1f} KB\")\n",
    "with open(os.path.join(OUTDIR, 'tflite_metrics.json'), 'w') as f:\n",
    "    json.dump(results, f, indent=2)\n",
    "print('Saved metrics to', os.path.join(OUTDIR, 'tflite_metrics.json'))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
